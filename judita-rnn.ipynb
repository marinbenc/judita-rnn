{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uzorak ima 81119 slova.\n",
      "Dike ter hvaljen'ja presvetoj Juditi,\n",
      "  smina nje stvore(n)'ja hoću govoriti;\n",
      "  zato ću moliti, Bože, tvoju svitlost,\n",
      "  ne hti(j) mi kratiti u tom punu milost.\n",
      "Ti s' on ki da kripost svakomu dilu nje\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = open(\"../input/judita.txt\", \"r\").read()\n",
    "\n",
    "# Treniranje na 30% podataka\n",
    "sample = data[:int(len(data))]\n",
    "\n",
    "print(\"Uzorak ima \" + str(len(sample)) + \" slova.\")\n",
    "print(sample[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0d12a9b1547f72594c0ebf7d7f6b050e43f0c1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unikatnih znakova: 66\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(list(set(sample)))\n",
    "print(\"Unikatnih znakova: \" + str(len(unique_chars)))\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(unique_chars))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d2ce841e2c2256c239961026196f6e1f113558e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dijelova: 27027\n",
      "Dike ter hvaljen'ja presvetoj Juditi,\n",
      "   + s\n",
      "e ter hvaljen'ja presvetoj Juditi,\n",
      "  smi + n\n",
      "er hvaljen'ja presvetoj Juditi,\n",
      "  smina  + n\n"
     ]
    }
   ],
   "source": [
    "part_len = 40\n",
    "step = 3\n",
    "\n",
    "parts = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(sample) - part_len, step):\n",
    "    # Podijeli tekst na niz dijelova koji se preklapaju, svakih `step` slova\n",
    "    # npr. \"Bok, ja sam Marin\" \", \"ja sam Marin Ben\", \"sam Marin Bencev\" ...\n",
    "    parts.append(sample[i : i + part_len])\n",
    "    # i za svaki taj dio spremi u `next_parts` sljedece slovo recenice\n",
    "    # npr. \"\"\n",
    "    next_chars.append(sample[i + part_len])\n",
    "    \n",
    "print(\"Dijelova: \" + str(len(parts)))\n",
    "for p in [parts[i] + \" + \" + next_chars[i] for i in range(3)]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "921340b58a988e0ca46bbbf44991d60b09ad1c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [ True False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False  True False False False False False False\n",
      "  False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "# Kodiraj input i output. Za svako slovo napravi niz boolova takav da su\n",
    "# sve vrijednosti false osim vrijednosti na indeksu tog slova.\n",
    "# Za output koristi indekse od next_chars. Tako da za svaki input \n",
    "# (koji je niz indeksa), output bude indeks sljedeceg slova.\n",
    "\n",
    "x = np.zeros((len(parts), part_len, len(unique_chars)), dtype=np.bool)\n",
    "y = np.zeros((len(parts), len(unique_chars)), dtype=np.bool)\n",
    "for i, part in enumerate(parts):\n",
    "    for j, char in enumerate(part):\n",
    "        x[i, j, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_chars[i]]] = 1\n",
    "    \n",
    "print(x[:1])\n",
    "print(y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "6b168628810d727996e5e909a08fdf3b96ae59a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(part_len, len(unique_chars)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, input_shape=(part_len, len(unique_chars))))\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "050572410be3c835668fb28bebc9dac1d96309d0"
   },
   "outputs": [],
   "source": [
    "# Za listu predvidjenih indeksa slova odaberi jedno slovo.\n",
    "# `temperature` odredjuje moguce odstupanje od najbolje \n",
    "# vrijednosti.\n",
    "def sample_preds(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0b2c19d930d69aa00a7dcec6e4bb9bcf7a1f674a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 39s - loss: 3.2223\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.22231, saving model to model.hdf5\n",
      "Epoch 2/50\n",
      " - 37s - loss: 2.6190\n",
      "\n",
      "Epoch 00002: loss improved from 3.22231 to 2.61899, saving model to model.hdf5\n",
      "Epoch 3/50\n",
      " - 37s - loss: 2.3450\n",
      "\n",
      "Epoch 00003: loss improved from 2.61899 to 2.34498, saving model to model.hdf5\n",
      "Epoch 4/50\n",
      " - 37s - loss: 2.2435\n",
      "\n",
      "Epoch 00004: loss improved from 2.34498 to 2.24347, saving model to model.hdf5\n",
      "Epoch 5/50\n",
      " - 37s - loss: 2.1755\n",
      "\n",
      "Epoch 00005: loss improved from 2.24347 to 2.17549, saving model to model.hdf5\n",
      "Epoch 6/50\n",
      " - 37s - loss: 2.1354\n",
      "\n",
      "Epoch 00006: loss improved from 2.17549 to 2.13543, saving model to model.hdf5\n",
      "Epoch 7/50\n",
      " - 37s - loss: 2.0850\n",
      "\n",
      "Epoch 00007: loss improved from 2.13543 to 2.08497, saving model to model.hdf5\n",
      "Epoch 8/50\n",
      " - 37s - loss: 2.0449\n",
      "\n",
      "Epoch 00008: loss improved from 2.08497 to 2.04488, saving model to model.hdf5\n",
      "Epoch 9/50\n",
      " - 37s - loss: 2.0020\n",
      "\n",
      "Epoch 00009: loss improved from 2.04488 to 2.00203, saving model to model.hdf5\n",
      "Epoch 10/50\n",
      " - 37s - loss: 1.9605\n",
      "\n",
      "Epoch 00010: loss improved from 2.00203 to 1.96051, saving model to model.hdf5\n",
      "Epoch 11/50\n",
      " - 37s - loss: 1.9193\n",
      "\n",
      "Epoch 00011: loss improved from 1.96051 to 1.91926, saving model to model.hdf5\n",
      "Epoch 12/50\n",
      " - 37s - loss: 1.8774\n",
      "\n",
      "Epoch 00012: loss improved from 1.91926 to 1.87743, saving model to model.hdf5\n",
      "Epoch 13/50\n",
      " - 37s - loss: 1.8293\n",
      "\n",
      "Epoch 00013: loss improved from 1.87743 to 1.82928, saving model to model.hdf5\n",
      "Epoch 14/50\n",
      " - 37s - loss: 1.7832\n",
      "\n",
      "Epoch 00014: loss improved from 1.82928 to 1.78319, saving model to model.hdf5\n",
      "Epoch 15/50\n",
      " - 37s - loss: 1.7271\n",
      "\n",
      "Epoch 00015: loss improved from 1.78319 to 1.72707, saving model to model.hdf5\n",
      "Epoch 16/50\n",
      " - 37s - loss: 1.6751\n",
      "\n",
      "Epoch 00016: loss improved from 1.72707 to 1.67510, saving model to model.hdf5\n",
      "Epoch 17/50\n",
      " - 37s - loss: 1.6134\n",
      "\n",
      "Epoch 00017: loss improved from 1.67510 to 1.61345, saving model to model.hdf5\n",
      "Epoch 18/50\n",
      " - 37s - loss: 1.5467\n",
      "\n",
      "Epoch 00018: loss improved from 1.61345 to 1.54668, saving model to model.hdf5\n",
      "Epoch 19/50\n",
      " - 37s - loss: 1.4706\n",
      "\n",
      "Epoch 00019: loss improved from 1.54668 to 1.47060, saving model to model.hdf5\n",
      "Epoch 20/50\n",
      " - 37s - loss: 1.3933\n",
      "\n",
      "Epoch 00020: loss improved from 1.47060 to 1.39332, saving model to model.hdf5\n",
      "Epoch 21/50\n",
      " - 37s - loss: 1.3132\n",
      "\n",
      "Epoch 00021: loss improved from 1.39332 to 1.31317, saving model to model.hdf5\n",
      "Epoch 22/50\n",
      " - 37s - loss: 1.2192\n",
      "\n",
      "Epoch 00022: loss improved from 1.31317 to 1.21919, saving model to model.hdf5\n",
      "Epoch 23/50\n",
      " - 37s - loss: 1.1420\n",
      "\n",
      "Epoch 00023: loss improved from 1.21919 to 1.14199, saving model to model.hdf5\n",
      "Epoch 24/50\n",
      " - 37s - loss: 1.0457\n",
      "\n",
      "Epoch 00024: loss improved from 1.14199 to 1.04570, saving model to model.hdf5\n",
      "Epoch 25/50\n",
      " - 37s - loss: 0.9595\n",
      "\n",
      "Epoch 00025: loss improved from 1.04570 to 0.95953, saving model to model.hdf5\n",
      "Epoch 26/50\n",
      " - 37s - loss: 0.8681\n",
      "\n",
      "Epoch 00026: loss improved from 0.95953 to 0.86813, saving model to model.hdf5\n",
      "Epoch 27/50\n",
      " - 37s - loss: 0.7924\n",
      "\n",
      "Epoch 00027: loss improved from 0.86813 to 0.79242, saving model to model.hdf5\n",
      "Epoch 28/50\n",
      " - 37s - loss: 0.7078\n",
      "\n",
      "Epoch 00028: loss improved from 0.79242 to 0.70783, saving model to model.hdf5\n",
      "Epoch 29/50\n",
      " - 37s - loss: 0.6484\n",
      "\n",
      "Epoch 00029: loss improved from 0.70783 to 0.64839, saving model to model.hdf5\n",
      "Epoch 30/50\n",
      " - 37s - loss: 0.5720\n",
      "\n",
      "Epoch 00030: loss improved from 0.64839 to 0.57202, saving model to model.hdf5\n",
      "Epoch 31/50\n",
      " - 37s - loss: 0.5160\n",
      "\n",
      "Epoch 00031: loss improved from 0.57202 to 0.51602, saving model to model.hdf5\n",
      "Epoch 32/50\n",
      " - 37s - loss: 0.4646\n",
      "\n",
      "Epoch 00032: loss improved from 0.51602 to 0.46462, saving model to model.hdf5\n",
      "Epoch 33/50\n",
      " - 37s - loss: 0.4021\n",
      "\n",
      "Epoch 00033: loss improved from 0.46462 to 0.40210, saving model to model.hdf5\n",
      "Epoch 34/50\n",
      " - 37s - loss: 0.3766\n",
      "\n",
      "Epoch 00034: loss improved from 0.40210 to 0.37657, saving model to model.hdf5\n",
      "Epoch 35/50\n",
      " - 37s - loss: 0.3272\n",
      "\n",
      "Epoch 00035: loss improved from 0.37657 to 0.32719, saving model to model.hdf5\n",
      "Epoch 36/50\n",
      " - 37s - loss: 0.2947\n",
      "\n",
      "Epoch 00036: loss improved from 0.32719 to 0.29472, saving model to model.hdf5\n",
      "Epoch 37/50\n",
      " - 37s - loss: 0.2750\n",
      "\n",
      "Epoch 00037: loss improved from 0.29472 to 0.27497, saving model to model.hdf5\n",
      "Epoch 38/50\n",
      " - 37s - loss: 0.2306\n",
      "\n",
      "Epoch 00038: loss improved from 0.27497 to 0.23062, saving model to model.hdf5\n",
      "Epoch 39/50\n",
      " - 37s - loss: 0.2277\n",
      "\n",
      "Epoch 00039: loss improved from 0.23062 to 0.22772, saving model to model.hdf5\n",
      "Epoch 40/50\n",
      " - 37s - loss: 0.2123\n",
      "\n",
      "Epoch 00040: loss improved from 0.22772 to 0.21227, saving model to model.hdf5\n",
      "Epoch 41/50\n",
      " - 37s - loss: 0.1893\n",
      "\n",
      "Epoch 00041: loss improved from 0.21227 to 0.18934, saving model to model.hdf5\n",
      "Epoch 42/50\n",
      " - 37s - loss: 0.1634\n",
      "\n",
      "Epoch 00042: loss improved from 0.18934 to 0.16345, saving model to model.hdf5\n",
      "Epoch 43/50\n",
      " - 37s - loss: 0.1669\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.16345\n",
      "Epoch 44/50\n",
      " - 36s - loss: 0.1594\n",
      "\n",
      "Epoch 00044: loss improved from 0.16345 to 0.15939, saving model to model.hdf5\n",
      "Epoch 45/50\n",
      " - 36s - loss: 0.1606\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.15939\n",
      "Epoch 46/50\n",
      " - 36s - loss: 0.1513\n",
      "\n",
      "Epoch 00046: loss improved from 0.15939 to 0.15127, saving model to model.hdf5\n",
      "Epoch 47/50\n",
      " - 37s - loss: 0.1567\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.15127\n",
      "Epoch 48/50\n",
      " - 36s - loss: 0.1236\n",
      "\n",
      "Epoch 00048: loss improved from 0.15127 to 0.12355, saving model to model.hdf5\n",
      "Epoch 49/50\n",
      " - 37s - loss: 0.1168\n",
      "\n",
      "Epoch 00049: loss improved from 0.12355 to 0.11682, saving model to model.hdf5\n",
      "Epoch 50/50\n",
      " - 36s - loss: 0.1214\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.11682\n"
     ]
    }
   ],
   "source": [
    "filepath = \"model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=50,\n",
    "              verbose=2,\n",
    "              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "4f56c6fc910e38388eb9b73426c3a21a09e6aa6d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bog, poprezaše: \"Jer sa nastoriti,\n",
      "  Adi se ne vriti vazza neće se sferi.\n",
      "  Bog nere postitaše zna čtu hrudu posti,\n",
      "  od rezim poljim živom, žive ka na ljih.\n",
      "Ni ter na ka visi, zimen'ja bustući\n",
      "  i ter ju vanje visto u puka svitu,\n",
      "  da je lepaši pro(j)ahu svak ga njih izdite.\n",
      "Čanost ogonj da njega ke prada jast.\n",
      "Da to prova žene u sčelju su zi(j)u.\n",
      "  Njih kim pokora, statim i živo(j)e.\n",
      "Zdi se vemari prav glavne odsteni,\n",
      "  trardi se rečari vizše pitil stanje.\n",
      "Toko di naj bili, kako ga da žilom sud\n",
      "Ozmore po bita, kazbi se goveriti\n",
      "Bogu se zrato(j)aše bi jar obraše,\n",
      "  od njim projim svom mora či svojahu,\n",
      "  ka Gje u nie stana varve ga predanjih\n",
      "  neće s' Mrirsajim, Bog jaš na porizaje.\n",
      "Kad Bog nje poje osta priv je me čili,\n",
      "  krazbi kako rina, seren'jame, čamo,\n",
      "  sila kako poti, poglečen'je opo(j)a\n",
      "  Bog se or stoja da za pro(j)ah vi(j)i\n",
      "  udimil u razih, leperi jud lipaše,\n",
      "  u trapik pritivu, hame na vista vase,\n",
      "  i svaka vadiru o plavce veniše,\n",
      "  za njega napase dade se mena mom\n",
      "  i te\n"
     ]
    }
   ],
   "source": [
    "start = random.randint(0, len(x) - 1)\n",
    "generated = ''\n",
    "part = sample[start : start + part_len]\n",
    "generated += part\n",
    "\n",
    "for i in range(1000):\n",
    "    x_pred = np.zeros((1, part_len, len(unique_chars)))\n",
    "    for j, char in enumerate(part):\n",
    "        x_pred[0, j, char_to_index[char]] = 1.\n",
    "        \n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample_preds(preds, 0.8)\n",
    "    next_char = index_to_char[next_index]\n",
    "    \n",
    "    generated += next_char\n",
    "    part = part[1:] + next_char\n",
    "    \n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
